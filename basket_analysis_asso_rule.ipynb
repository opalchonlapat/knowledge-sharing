{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51d6f36b-8f9e-4ed6-bb63-025fd0d883ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Market Basket Analysis and Association Rule\n",
    "---\n",
    "Market Basket Analysis is one of the key techniques used by large retailers to uncover associations between items. It works by looking for combinations of items that occur together frequently in transactions. To put it another way, it allows retailers to identify relationships between the items that people buy.\n",
    "\n",
    "![](https://editor.analyticsvidhya.com/uploads/13952Market-basket-analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8e7a4cd-98ad-4d1b-9377-04a62e6af067",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Frequent Itemset Mining (FIM)\n",
    "---\n",
    "Frequent Itemset Mining is a method that comes under the market basket analysis. Frequent Itemset mining aims to find the regularities in the transactions performed by the consumers. In terms of the supermarket, we can say regularities in the shopping behaviour of customers. \n",
    "\n",
    "Basically, frequent itemset mining is a procedure that helps in finding the sets of products that are frequently bought together. Found frequent itemsets can be applied on the procedure of recommendation system, fraud detection or using them we can improve the arrangement of the products in the shelves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b711a0e-b2c9-4f73-8d27-37e19ad16a02",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### [Metric] Support\n",
    "Support is a measure that indicates the frequent appearance of a variable set or itemset in a database. Let X be the itemset and T a set of transactions in  then the support of X with respect to T can be measured as  \n",
    "![](https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/09/image-126.png)  \n",
    "Basically, the above measure tells the proportion of T transactions in the database which contains the item set X. From above the given table support for itemset  {product 1, product 2} will be ⅖ or 0.4. Because the itemset has appeared only in 2 transactions and the total count of transactions is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b317108-b707-438e-8644-6dc86a4e6b77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Apriori\n",
    "---\n",
    "In the process of Frequent Itemset Mining, the Apriori algorithm first considers every single item as an itemset and counts the support from their frequency in the database, and then captures those who have support equal to or more than the minimum support threshold. In this process extraction of each frequent itemset requires the scanning of the entire database by the algorithm until no more itemsets are left with more than the minimum threshold support.  \n",
    "![](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1530898581/Image_5_qcih6b.png)\n",
    "![](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1530898581/Image_6_ee2pss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a91962b1-22c0-4da6-8c6b-38506d5435e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-8bf9403a-0535-46fc-bc08-c4650b888a70/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afcacd8d-aa42-4564-844e-4c55f5a501c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
        "text/plain": ""
       },
       "datasetInfos": [],
       "executionCount": null,
       "metadata": {
        "kernelSessionId": "c487c0e7-bca0989e6c404d082d26456a"
       },
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "160854c6-2856-4157-8c96-c19541e56cee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For implementation, I am making a dataset of 11 products and using the mlxtend library for making a Frequent dataset using the apriori algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7abf2e2-da14-4ff0-bf69-07e5929579a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_id</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txn1</td>\n",
       "      <td>[product7, product9, product8, product6, produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txn2</td>\n",
       "      <td>[product3, product9, product8, product6, produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>txn3</td>\n",
       "      <td>[product7, product1, product6, product4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txn4</td>\n",
       "      <td>[product7, product10, product2, product6, prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>txn5</td>\n",
       "      <td>[product2, product9, product6, product5, produ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txn_id</th>\n      <th>items</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>txn1</td>\n      <td>[product7, product9, product8, product6, produ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>txn2</td>\n      <td>[product3, product9, product8, product6, produ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>txn3</td>\n      <td>[product7, product1, product6, product4]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>txn4</td>\n      <td>[product7, product10, product2, product6, prod...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>txn5</td>\n      <td>[product2, product9, product6, product5, produ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "txn_id = ['txn1', 'txn2', 'txn3', 'txn4', 'txn5']\n",
    "dataset = [['product7', 'product9', 'product8', 'product6', 'product4', 'product11'],\n",
    "           ['product3', 'product9', 'product8', 'product6', 'product4', 'product11'],\n",
    "           ['product7', 'product1', 'product6', 'product4'],\n",
    "           ['product7', 'product10', 'product2', 'product6', 'product11'],\n",
    "           ['product2', 'product9', 'product6', 'product5', 'product4']]\n",
    "df = pd.DataFrame({'txn_id': txn_id, 'items': dataset})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baf644c4-289c-466d-872c-0e7c11921a35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product1</th>\n",
       "      <th>product10</th>\n",
       "      <th>product11</th>\n",
       "      <th>product2</th>\n",
       "      <th>product3</th>\n",
       "      <th>product4</th>\n",
       "      <th>product5</th>\n",
       "      <th>product6</th>\n",
       "      <th>product7</th>\n",
       "      <th>product8</th>\n",
       "      <th>product9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product1</th>\n      <th>product10</th>\n      <th>product11</th>\n      <th>product2</th>\n      <th>product3</th>\n      <th>product4</th>\n      <th>product5</th>\n      <th>product6</th>\n      <th>product7</th>\n      <th>product8</th>\n      <th>product9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "con = TransactionEncoder()\n",
    "con_arr = con.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(con_arr, columns = con.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e77074d0-400f-40da-ac5f-36ada86ce2fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next, I will be making itemsets with at least 60% support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55da979a-9234-46f9-84c9-1903c1039cc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(product6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(product4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(product6, product4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(product11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(product7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(product9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(product6, product11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(product9, product4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(product6, product7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(product9, product6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(product9, product4, product6)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>support</th>\n      <th>itemsets</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>(product6)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.8</td>\n      <td>(product4)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.8</td>\n      <td>(product6, product4)</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.6</td>\n      <td>(product11)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.6</td>\n      <td>(product7)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.6</td>\n      <td>(product9)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.6</td>\n      <td>(product6, product11)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.6</td>\n      <td>(product9, product4)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.6</td>\n      <td>(product6, product7)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.6</td>\n      <td>(product9, product6)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.6</td>\n      <td>(product9, product4, product6)</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "apriori(df, min_support=0.6, use_colnames=True).sort_values('support', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e796f56-84bf-4323-9135-d86d0a503dc3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here we can see the itemsets with minimum support of 60% with the column indices which can be used for some downstream operations such as making marketing strategies like giving some offers in buying combinations of products.\n",
    "\n",
    "Now let’s have a look at FP Growth Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5aed988-ec03-4020-a5d8-5c16474a7058",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### FP-Growth\n",
    "---\n",
    "The FP-Growth Algorithm is an alternative way to find frequent item sets without using candidate generations, thus improving performance. As you can see from Apriori algorithm, it generate candidate to create itemsets by scanning whole database go back and forth. That's why FP-Growth faster. The core of this method is the usage of a special data structure named frequent-pattern tree (FP-tree), which retains the item set association information.\n",
    "\n",
    "#### FP-Tree\n",
    "![](https://static.javatpoint.com/tutorial/data-mining/images/fp-growth-algorithm-in-data-mining.png)\n",
    "\n",
    "The frequent-pattern tree (FP-tree) is a compact data structure that stores quantitative information about frequent patterns in a database. Each transaction is read and then mapped onto a path in the FP-tree. This is done until all transactions have been read. Different transactions with common subsets allow the tree to remain compact because their paths overlap.\n",
    "\n",
    "A frequent Pattern Tree is made with the initial item sets of the database. The purpose of the FP tree is to mine the most frequent pattern. Each node of the FP tree represents an item of the item set.\n",
    "\n",
    "The root node represents null, while the lower nodes represent the item sets. The associations of the nodes with the lower nodes, that is, the item sets with the other item sets, are maintained while forming the tree.\n",
    "\n",
    "**FP-tree structure given below:**\n",
    "\n",
    "1. One root is labelled as \"null\" with a set of item-prefix subtrees as children and a frequent-item-header table.\n",
    "2. Each node in the item-prefix subtree consists of three fields:\n",
    "    - Item-name: registers which item is represented by the node;\n",
    "    - Count: the number of transactions represented by the portion of the path reaching the node;\n",
    "    - Node-link: links to the next node in the FP-tree carrying the same item name or null if there is none.\n",
    "3. Each entry in the frequent-item-header table consists of two fields:\n",
    "    - Item-name: as the same to the node;\n",
    "    - Head of node-link: a pointer to the first node in the FP-tree carrying the item name.\n",
    "    \n",
    "Additionally, the frequent-item-header table can have the count support for an item. The below diagram is an example of a best-case scenario that occurs when all transactions have the same itemset; the size of the FP-tree will be only a single branch of nodes.\n",
    "\n",
    "**The FP-tree is constructed as follows:**\n",
    "\n",
    "1. The first step is to scan the database to find the occurrences of the itemsets in the database. This step is the same as the first step of Apriori. The count of 1-itemsets in the database is called support count or frequency of 1-itemset.\n",
    "2. The second step is to construct the FP tree. For this, create the root of the tree. The root is represented by null.\n",
    "3. The next step is to scan the database again and examine the transactions. Examine the first transaction and find out the itemset in it. The itemset with the max count is taken at the top, and then the next itemset with the lower count. It means that the branch of the tree is constructed with transaction itemsets in descending order of count.\n",
    "4. The next transaction in the database is examined. The itemsets are ordered in descending order of count. If any itemset of this transaction is already present in another branch, then this transaction branch would share a common prefix to the root.\n",
    "This means that the common itemset is linked to the new node of another itemset in this transaction.\n",
    "5. Also, the count of the itemset is incremented as it occurs in the transactions. The common node and new node count are increased by 1 as they are created and linked according to transactions.\n",
    "6. The next step is to mine the created FP Tree. For this, the lowest node is examined first, along with the links of the lowest nodes. The lowest node represents the frequency pattern length 1. From this, traverse the path in the FP Tree. This path or paths is called a conditional pattern base.\n",
    "A conditional pattern base is a sub-database consisting of prefix paths in the FP tree occurring with the lowest node (suffix).\n",
    "7. Construct a Conditional FP Tree, formed by a count of itemsets in the path. The itemsets meeting the threshold support are considered in the Conditional FP Tree.\n",
    "8. Frequent Patterns are generated from the Conditional FP Tree.\n",
    "\n",
    "Using this algorithm, the FP-tree is constructed in two database scans. The first scan collects and sorts the set of frequent items, and the second constructs the FP-Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cf8743a-9e58-486f-b289-a988e6d110a4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Example:**\n",
    "\n",
    "Support threshold=50%, Confidence= 60%\n",
    "\n",
    "**Table1:**  \n",
    "| Transaction | List of items |\n",
    "|-------------|---------------|\n",
    "| T1          | I1,I2,I3      |\n",
    "| T2          | I2,I3,I4      |\n",
    "| T3          | I4,I5         |\n",
    "| T4          | I1,I2,I4      |\n",
    "| T5          | I1,I2,I3,I5   |\n",
    "| T6          | I1,I2,I3,I4   |\n",
    "\n",
    "Solution: Support threshold=50% => 0.5*6= 3 => min_sup=3\n",
    "\n",
    "**Table 2: Count of each item**  \n",
    "| Item | Count |\n",
    "|------|-------|\n",
    "| I1   | 4     |\n",
    "| I2   | 5     |\n",
    "| I3   | 4     |\n",
    "| I4   | 4     |\n",
    "| I5   | 2     |\n",
    "\n",
    "**Table 3: Sort the itemset in descending order.**  \n",
    "| Item | Count |\n",
    "|------|-------|\n",
    "| I2   | 5     |\n",
    "| I1   | 4     |\n",
    "| I3   | 4     |\n",
    "| I4   | 4     |\n",
    "\n",
    "Let's build the FP tree in the following steps, such as:\n",
    "\n",
    "1. Considering the root node null.\n",
    "2. The first scan of Transaction T1: I1, I2, I3 contains three items {I1:1}, {I2:1}, {I3:1}, where I2 is linked as a child, I1 is linked to I2 and I3 is linked to I1.\n",
    "3. T2: I2, I3, and I4 contain I2, I3, and I4, where I2 is linked to root, I3 is linked to I2 and I4 is linked to I3. But this branch would share the I2 node as common as it is already used in T1.\n",
    "4. Increment the count of I2 by 1, and I3 is linked as a child to I2, and I4 is linked as a child to I3. The count is {I2:2}, {I3:1}, {I4:1}.\n",
    "5. T3: I4, I5. Similarly, a new branch with I5 is linked to I4 as a child is created.\n",
    "6. T4: I1, I2, I4. The sequence will be I2, I1, and I4. I2 is already linked to the root node. Hence it will be incremented by 1. Similarly I1 will be incremented by 1 as it is already linked with I2 in T1, thus {I2:3}, {I1:2}, {I4:1}.\n",
    "7. T5:I1, I2, I3, I5. The sequence will be I2, I1, I3, and I5. Thus {I2:4}, {I1:3}, {I3:2}, {I5:1}.\n",
    "8. T6: I1, I2, I3, I4. The sequence will be I2, I1, I3, and I4. Thus {I2:5}, {I1:4}, {I3:3}, {I4 1}.\n",
    "\n",
    "![](https://static.javatpoint.com/tutorial/data-mining/images/fp-growth-algorithm-in-data-mining3.png)\n",
    "\n",
    "Mining of FP-tree is summarized below:\n",
    "\n",
    "1. The lowest node item, I5, is not considered as it does not have a min support count. Hence it is deleted.\n",
    "2. The next lower node is I4. I4 occurs in 2 branches , {I2,I1,I3,I4:1},{I2,I3,I4:1}. Therefore considering I4 as suffix the prefix paths will be {I2, I1, I3:1}, {I2, I3: 1} this forms the conditional pattern base.\n",
    "3. The conditional pattern base is considered a transaction database, and an FP tree is constructed. This will contain {I2:2, I3:2}, I1 is not considered as it does not meet the min support count.\n",
    "4. This path will generate all combinations of frequent patterns : {I2,I4:2},{I3,I4:2},{I2,I3,I4:2}\n",
    "5. For I3, the prefix path would be: {I2,I1:3},{I2:1}, this will generate a 2 node FP-tree : {I2:4, I1:3} and frequent patterns are generated: {I2,I3:4}, {I1:I3:3}, {I2,I1,I3:3}.\n",
    "6. For I1, the prefix path would be: {I2:4} this will generate a single node FP-tree: {I2:4} and frequent patterns are generated: {I2, I1:4}.\n",
    "\n",
    "| Item | Conditional Pattern Base | Conditional FP-tree | Frequent Patterns Generated        |\n",
    "|------|--------------------------|---------------------|------------------------------------|\n",
    "| I4   | {I2,I1,I3:1},{I2,I3:1}   | {I2:2, I3:2}        | {I2,I4:2},{I3,I4:2},{I2,I3,I4:2}   |\n",
    "| I3   | {I2,I1:3},{I2:1}         | {I2:4, I1:3}        | {I2,I3:4}, {I1:I3:3}, {I2,I1,I3:3} |\n",
    "| I1   | {I2:4}                   | {I2:4}              | {I2,I1:4}                          |\n",
    "\n",
    "The diagram given below depicts the conditional FP tree associated with the conditional node I3.\n",
    "\n",
    "![](https://static.javatpoint.com/tutorial/data-mining/images/fp-growth-algorithm-in-data-mining4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e804261-41dc-4fbe-b468-e6aaf5bf099e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: [['product7|product9|product8|product6|product4|product11'],\n",
      " ['product3|product9|product8|product6|product4|product11'],\n",
      " ['product7|product1|product6|product4'],\n",
      " ['product7|product10|product2|product6|product11'],\n",
      " ['product2|product9|product6|product5|product4']]"
     ]
    }
   ],
   "source": [
    "new_dataset = []\n",
    "\n",
    "for v in dataset:\n",
    "    new_dataset.append([\"|\".join(v)])\n",
    "\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6573bd1c-21f8-4762-b4f9-8e8b86f4ce2e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+\n",
      "|items                                                        |\n",
      "+-------------------------------------------------------------+\n",
      "|[product7, product9, product8, product6, product4, product11]|\n",
      "|[product3, product9, product8, product6, product4, product11]|\n",
      "|[product7, product1, product6, product4]                     |\n",
      "|[product7, product10, product2, product6, product11]         |\n",
      "|[product2, product9, product6, product5, product4]           |\n",
      "+-------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField(\"items\", StringType(), True)])\n",
    "\n",
    "spark_df = spark.createDataFrame(data=new_dataset, schema=schema)\n",
    "spark_df = spark_df.withColumn('items', split(col('items'), r'\\|'))\n",
    "spark_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d57e4585-23a6-473b-be3e-0510911a30ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----+-------+\n",
      "|items                         |freq|support|\n",
      "+------------------------------+----+-------+\n",
      "|[product6]                    |5   |1.0    |\n",
      "|[product4]                    |4   |0.8    |\n",
      "|[product4, product6]          |4   |0.8    |\n",
      "|[product11]                   |3   |0.6    |\n",
      "|[product7]                    |3   |0.6    |\n",
      "|[product11, product6]         |3   |0.6    |\n",
      "|[product9]                    |3   |0.6    |\n",
      "|[product7, product6]          |3   |0.6    |\n",
      "|[product9, product4]          |3   |0.6    |\n",
      "|[product9, product4, product6]|3   |0.6    |\n",
      "|[product9, product6]          |3   |0.6    |\n",
      "+------------------------------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fp = FPGrowth(minSupport=0.6)\n",
    "fpm = fp.fit(spark_df)\n",
    "fpm.freqItemsets.sort(\"freq\", ascending=False).withColumn('support', col('freq')/5).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac042891-65b3-42e9-b80e-cfbe45950d3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Difference between Apriori and FP Growth\n",
    "| Apriori                                                                                                                                | FP Growth                                                                                 |\n",
    "|----------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
    "| Apriori generates frequent patterns by making the itemsets using pairings such as single item set, double itemset, and triple itemset. | FP Growth generates an FP-Tree for making frequent patterns.                              |\n",
    "| Apriori uses candidate generation where frequent subsets are extended one item at a time.                                              | FP-growth generates a conditional FP-Tree for every item in the data.                     |\n",
    "| Since apriori scans the database in each step, it becomes time-consuming for data where the number of items is larger.                 | FP-tree requires only one database scan in its beginning steps, so it consumes less time. |\n",
    "| A converted version of the database is saved in the memory                                                                             | A set of conditional FP-tree for every item is saved in the memory                        |\n",
    "| It uses a breadth-first search                                                                                                         | It uses a depth-first search.                                                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b594e87d-1160-478f-8c5f-3f9987861786",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Association Rule\n",
    "---\n",
    "![](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1530898580/Image_1_ip8nzc.png)\n",
    "\n",
    "Association rule mining is a technique used to identify patterns in large data sets. It involves finding relationships between variables in the data and using those relationships to make predictions or decisions. The goal of association rule mining is to uncover rules that describe the relationships between different items in the data set.\n",
    "\n",
    "For example, consider a dataset of transactions at a grocery store. Association rule mining could be used to identify relationships between items that are frequently purchased together. For example, the rule \"If a customer buys bread, they are also likely to buy milk\" is an association rule that could be mined from this data set. We can use such rules to inform decisions about store layout, product placement, and marketing efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76b15a32-d90b-46c9-9db3-f5d2c129a581",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Support\n",
    "Support is a measure of how frequently an item or itemset appears in the dataset. It is calculated as the number of transactions containing the item(s) divided by the total number of transactions in the dataset. High support indicates that an item or itemset is common in the dataset, while low support indicates that it is rare.\n",
    "\n",
    "![](https://res.cloudinary.com/dyd911kmh/image/upload/v1674491861/Support_Formula_e4d9c995bb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dd20b65-8b22-4a4b-aa6c-647845035b0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Confidence\n",
    "Confidence is a measure of the strength of the association between two items. It is calculated as the number of transactions containing both items divided by the number of transactions containing the first item. High confidence indicates that the presence of the first item is a strong predictor of the presence of the second item.\n",
    "\n",
    "![](https://res.cloudinary.com/dyd911kmh/image/upload/v1674491862/Confidence_Formula_eade731502.png)\n",
    "\n",
    "![](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1551286006/APRIORI3_r4im8b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1619c14a-c430-4553-835e-2813d2d4ed29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Lift\n",
    "Lift is a measure of the strength of the association between two items, taking into account the frequency of both items in the dataset. It is calculated as the confidence of the association divided by the support of the second item. Lift is used to compare the strength of the association between two items to the expected strength of the association if the items were independent. \n",
    "\n",
    "A lift value greater than 1 indicates that the association between two items is stronger than expected based on the frequency of the individual items. This suggests that the association may be meaningful and worth further investigation. A lift value less than 1 indicates that the association is weaker than expected and may be less reliable or less significant.\n",
    "\n",
    "![](https://res.cloudinary.com/dyd911kmh/image/upload/v1674491862/Lift_Formula_0c1b28e4d5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be6c2a07-3e90-48ad-acc3-2b8eb6566a8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+----+-------+\n",
      "|          antecedent|consequent|confidence|lift|support|\n",
      "+--------------------+----------+----------+----+-------+\n",
      "|         [product11]|[product6]|       1.0| 1.0|    0.6|\n",
      "|          [product4]|[product6]|       1.0| 1.0|    0.8|\n",
      "|          [product6]|[product4]|       0.8| 1.0|    0.8|\n",
      "|          [product7]|[product6]|       1.0| 1.0|    0.6|\n",
      "|          [product9]|[product4]|       1.0|1.25|    0.6|\n",
      "|          [product9]|[product6]|       1.0| 1.0|    0.6|\n",
      "|[product9, product4]|[product6]|       1.0| 1.0|    0.6|\n",
      "|[product9, product6]|[product4]|       1.0|1.25|    0.6|\n",
      "+--------------------+----------+----------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fpm.associationRules.sort(\"antecedent\", \"consequent\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fbc533c-6630-4025-bdc3-cf216cdd3159",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## References\n",
    "---\n",
    "- [FP Growth Algorithm in Data Mining](https://www.javatpoint.com/fp-growth-algorithm-in-data-mining#:~:text=What%20is%20FP%20Growth%20Algorithm,divide%2Dand%2Dconquer%20strategy.)\n",
    "- [Apriori vs FP-Growth in Market Basket Analysis – A Comparative Guide](https://analyticsindiamag.com/apriori-vs-fp-growth-in-market-basket-analysis-a-comparative-guide/#:~:text=Apriori%20uses%20candidate%20generation%20where,number%20of%20items%20is%20larger.)\n",
    "- [Market Basket Analysis using R](https://www.datacamp.com/tutorial/market-basket-analysis-r)\n",
    "- [Market Basket Analysis: A Comprehensive Guide for Businesses](https://www.analyticsvidhya.com/blog/2021/10/a-comprehensive-guide-on-market-basket-analysis/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "369e66d9-a59b-4606-b09f-ca9eee0e49e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "basket_analysis_asso_rule",
   "notebookOrigID": 1334080127493768,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
